[project]
name = "scope-vlm-ollama"
version = "0.1.0"
description = "Ollama VLM plugin: queries vision models, injects prompts, overlays text, with UDP preâ†’post support"
requires-python = ">=3.12"
dependencies = ["scope-bus", "scope-language"]

[project.entry-points."scope"]
scope_vlm_ollama = "scope_vlm_ollama"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/scope_vlm_ollama"]
